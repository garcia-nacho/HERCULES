library(seqinr)
arg=commandArgs(TRUE)
#1: Cutoff 0.1
#2: start 1250
#3: end 2250
#4: poicurrent "auto"

nstart<-as.numeric(arg[1])
nend<- as.numeric(arg[2])
input.path<-"/Reference"

# wu<-seqinr::read.fasta("/media/nacho/Data/DockerImages/Wastewater_SARS-CoV-2/CommonFiles/reference/SpikeRef.fa")
# nstart<-1250
# nend<-2250
# input.path<-"/media/nacho/Data/DockerImages/HERCULES/CommonFiles/reference/newref"


wu<-seqinr::read.fasta("/home/docker/CommonFiles/reference/SpikeRef.fa")

input.file <- list.files(input.path, pattern = "*\\.fa.*",full.names = TRUE)
wu<-wu[[1]][c(nstart:nend)]

if(length(input.file)==1){
refs<-seqinr::read.fasta(input.file)  
refdf<-toupper(unlist(lapply(refs,function(x)paste(x[nstart:nend], collapse = ""))))
refdf<-as.data.frame(as.character(refdf))
colnames(refdf)<-"#query_msa"
refdf$ref_msa<-toupper(paste(wu,collapse = ""))

uniquerefs<-unique(refdf$`#query_msa`)
lineage.id<-gsub(".*_","",names(refs))
lin.vec<-vector()
for (i in 1:length(uniquerefs)) {
  
  lineages<- lineage.id[which(refdf$`#query_msa`==uniquerefs[i])]
  lineages<-strsplit(lineages,"\\.")
  noe<-max(unlist(lapply(lineages, length)))
  maxnoe<-noe
  running<-TRUE
  while(running){
    new.lineages<- unlist(lapply(lineages, function(x) paste(x[(1:min(length(x),noe))], collapse = ".") ))
    ratio<- max(table(new.lineages))/length(new.lineages)
    if(ratio>0.9){
      new.lin<-names(table(new.lineages)[which(table(new.lineages)==max(table(new.lineages)))])[1]
      #unique.index<-c(unique.index,which(df$hash==uniqueregions[i])[1])
      running<-FALSE
      
    }else{
      new.lin<-NA
      if(noe==1) running<-FALSE
    }
    noe<-noe-1
  }
  if(is.na(new.lin)){
    lin.vec<-c(lin.vec, paste("NA_SQ",i,sep = ""))
  }else{
    
    if(maxnoe==noe+1){
      lin.vec<-c(lin.vec, paste(new.lin,"_SQ",i,sep = ""))
    }else{
      lin.vec<-c(lin.vec, paste(new.lin,".X_SQ",i,sep = ""))  
    }
  }
  
}

if(length(which(duplicated(refdf$`#query_msa`)))>0) refdf<-refdf[-which(duplicated(refdf$`#query_msa`)), ]
  
print("Writing references")
write.table(refdf, "/home/docker/CommonFiles/reference/MSA_Refs.tsv", row.names = FALSE, quote = FALSE, sep = "\t")
write.table(lin.vec, "/home/docker/CommonFiles/reference/MSA_RefsID.csv", row.names = FALSE)
try(system("rm /home/docker/CommonFiles/reference/MSA_Refs.tsv.gz"))
system("gzip -f /home/docker/CommonFiles/reference/MSA_Refs.tsv")
  
poi<-c(nstart:nend)

noise.ref<-do.call(rbind, refs)
noisecalc<-function(x){
  if(length(which(x=="n"))>0)x<-x[-which(x=="n")]
  return(1-(as.numeric(table(x)[(which(table(x)==max(table(x))))]/sum(table(x))))) 
}
noiseunique<-apply(noise.ref,2,noisecalc)
noise.co<-which(noiseunique>0.01)
if(length(noise.co>0)) noise.co<-noise.co[which(noise.co>=nstart & noise.co<=nend)]
if(length(noise.co>0)){
  noise.co<-noise.co-nstart+1
  write.csv(noise.co,"/home/docker/CommonFiles/reference/NoiseRefs.csv",row.names = FALSE)
}else{
  write.csv(1841,"/home/docker/CommonFiles/reference/NoiseRefs.csv",row.names = FALSE)
}

#Cleaning identical spikes.

lineages<-unique(gsub(".*_","", names(refs)))

bases<-c("a","t","c","g","-")
#Generation of the probability matrix

pb<-txtProgressBar(min = 1, max = length(poi),initial = 1)
for (i in 1:length(poi)) {
  setTxtProgressBar(pb,i)
  dummym<-matrix(0, ncol = length(lineages), nrow = 5 )
  
  base.m<-lapply(refs, function(x)x[poi[i]])  
  names(base.m)<-gsub(".*_","", names(base.m))
  base.m<-unlist(base.m)
  base.m2<-match(base.m, c("a","t","c","g","-"))
  names(base.m2)<-names(base.m)
  
  for (j in 1:length(lineages)) {
    for (k in c(1:5)) {
      dummym[k,j]<-length(which(names(base.m2)==lineages[j] & base.m2==k))/ length(which(names(base.m2)==lineages[j]))
    }
  }
  
  dummym<-as.data.frame(dummym)
  colnames(dummym)<-lineages
  rownames(dummym)<-paste(poi[i],c("A","T","C","G","D"),sep = "")
  if(!exists("dummy.out")){ 
    dummy.out<-dummym
  }else{
    dummy.out<-rbind(dummy.out, dummym)
  }
}

print("Writing Probability matrix")
write.csv(dummy.out, "/home/docker/CommonFiles/reference/ProbMatrix.csv" )

}
